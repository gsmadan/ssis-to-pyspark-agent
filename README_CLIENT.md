# SSIS to PySpark Converter - User Guide

## Welcome!

This tool automatically converts your SSIS packages (.dtsx files) into PySpark code that can run in Azure Databricks.

**Key Features:**
- Converts SSIS packages to PySpark automatically
- 100% mapping coverage for common SSIS components
- Generates production-ready Python code
- No Python installation required (standalone .exe)

---

## ğŸš€ Quick Start

### Step 1: Prepare Your Files

1. Create a folder for your SSIS packages (e.g., `C:\SSIS_Packages\`)
2. Copy your .dtsx files into this folder

### Step 2: Run the Converter

**Option A: Convert a Single Package**
```cmd
ssis_to_pyspark_converter.exe C:\SSIS_Packages\MyPackage.dtsx
```

**Option B: Convert All Packages in a Folder**
```cmd
ssis_to_pyspark_converter.exe C:\SSIS_Packages\
```

### Step 3: Find Your Results

After conversion, check the `output\` folder:

```
output/
â”œâ”€â”€ pyspark_code/        # Your converted PySpark code (*.py files)
â”œâ”€â”€ parsed_json/         # Package details in JSON format
â”œâ”€â”€ mapping_details/     # Conversion statistics
â””â”€â”€ analysis/            # Conversion summary report
```

**Main files you need**: `output\pyspark_code\*.py`

---

## ğŸ“– Usage Examples

### Example 1: Convert One Package
```cmd
ssis_to_pyspark_converter.exe MyETL.dtsx
```

**Output:**
- `output\pyspark_code\MyETL_pyspark.py` - Your PySpark code

### Example 2: Convert Multiple Packages
```cmd
ssis_to_pyspark_converter.exe C:\SSIS_Packages\
```

**Output:**
- One `.py` file for each .dtsx package
- All in `output\pyspark_code\` folder

### Example 3: Use Custom Output Folder
```cmd
ssis_to_pyspark_converter.exe MyETL.dtsx --output MyResults\
```

**Output:**
- Files go to `MyResults\pyspark_code\` instead

---

## âœ… What to Do Next

### 1. Review the Generated Code

Open the generated Python file in `output\pyspark_code\`:
- Review the conversion
- Check for TODO comments
- Verify the logic matches your SSIS package

### 2. Update Connection Details

Find and update these placeholders in the generated code:
```python
# BEFORE (in generated code):
connection_url = "jdbc:sqlserver://server:1433;databaseName=database"
username = "username"  # TODO: Set actual username
password = "password"  # TODO: Set actual password

# AFTER (your updates):
connection_url = "jdbc:sqlserver://myserver:1433;databaseName=mydb"
username = "actual_user"
password = "actual_password"
```

**Tip**: Use Databricks secrets instead of hardcoding passwords!

### 3. Deploy to Databricks

1. Log into your Azure Databricks workspace
2. Create a new notebook or upload the .py file
3. Update the connection credentials
4. Run the code to test
5. Compare results with your SSIS package

### 4. Integrate with Azure Data Factory

1. Create an ADF pipeline
2. Add a Databricks Notebook activity
3. Point it to your converted PySpark notebook
4. Configure triggers and schedule

---

## ğŸ“Š Understanding the Output

### PySpark Code File

**File**: `output\pyspark_code\YourPackage_pyspark.py`

**Contents**:
- Complete PySpark script
- Spark session initialization
- Connection configurations
- SQL tasks converted
- Data flows with transformations
- Comments and TODOs for manual steps

**Example**:
```python
# Initialize Spark Session
spark = SparkSession.builder \
    .appName("YourPackage_Conversion") \
    .getOrCreate()

# Read from SQL Server
df = spark.read \
    .format("jdbc") \
    .option("url", "jdbc:sqlserver://...") \
    .option("dbtable", "your_table") \
    .load()

# Apply transformations
df = df.withColumn("new_column", current_timestamp())
df = df.filter(col("status") == "Active")

# Write results
df.write.mode("overwrite").parquet("output_path")
```

### Mapping Details

**File**: `output\mapping_details\YourPackage_mapping.json`

**Contents**:
- Mapping statistics (success rate)
- Component details
- What was mapped
- Recommendations

### Conversion Summary

**File**: `output\analysis\conversion_summary.json`

**Contents**:
- Overall statistics
- List of all converted packages
- Success/failure status
- Timestamp

---

## âš ï¸ Important Notes

### Manual Steps Required

After conversion, you'll need to:

1. **Update Credentials**
   - Replace placeholder usernames/passwords
   - Use Databricks secrets recommended

2. **Review Transformations**
   - Check complex expressions
   - Verify conditional logic
   - Test with sample data

3. **Specify Join Conditions**
   - Lookup transformations show the query
   - You need to specify the join columns
   - Example: `df.id == lookup_df.id`

4. **Update Destination Tables**
   - Some destinations may show "Unknown"
   - Update with actual table names

### What's Automatically Handled

âœ… **Expression Translation**
- SSIS functions â†’ PySpark functions
- `GETDATE()` â†’ `current_timestamp()`
- Column references properly converted

âœ… **DataFrame Operations**
- Derived columns â†’ `.withColumn()`
- Conditional splits â†’ `.filter()`
- Lookups â†’ `.join()`
- Aggregates â†’ `.groupBy().agg()`

âœ… **SQL Tasks**
- CREATE TABLE statements
- INSERT statements  
- SELECT queries
- All converted to `spark.sql()`

---

## ğŸ†˜ Getting Help

### Check the Log File
```cmd
type ssis_converter.log
```

Look for:
- [ERROR] messages - Problems during conversion
- [WARNING] messages - Items needing attention
- [OK] messages - Successful steps

### Common Questions

**Q: Why are some values "TODO"?**
A: These require manual input (like passwords, join conditions). Review and update them.

**Q: Will the PySpark code work immediately?**
A: It's syntactically correct but needs credentials and may need join conditions specified.

**Q: How do I know if conversion was successful?**
A: Check the summary at the end. "Successful: 1, Failed: 0" means success!

**Q: What if my package has custom components?**
A: The tool handles all standard SSIS components. Custom components may need manual implementation.

---

## ğŸ“ Support

### Files to Check
1. **Log file**: `ssis_converter.log`
2. **Generated code**: `output\pyspark_code\*.py`
3. **Summary**: `output\analysis\conversion_summary.json`

### What to Provide if Reporting Issues
- The log file (`ssis_converter.log`)
- Input package name
- Error messages
- What you expected vs. what you got

---

## âœ¨ Tips for Success

1. **Start Small**: Convert one simple package first to familiarize yourself
2. **Review Code**: Always review generated code before deploying
3. **Test Thoroughly**: Test with sample data in Databricks before production
4. **Use Secrets**: Never hardcode passwords - use Databricks secrets
5. **Compare Results**: Validate that Databricks produces same results as SSIS
6. **Keep Logs**: Save conversion logs for reference

---

## ğŸ¯ Success Checklist

Before deploying to production:
- [ ] Converted all SSIS packages successfully
- [ ] Reviewed all generated PySpark code
- [ ] Updated all connection credentials
- [ ] Specified all join conditions
- [ ] Tested in Databricks with sample data
- [ ] Compared results with SSIS (validation)
- [ ] Integrated with ADF pipeline
- [ ] Documented any manual changes
- [ ] Got approval from stakeholders

---

## ğŸ“‹ Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SSIS to PySpark Converter - Quick Reference     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Convert One Package:                            â”‚
â”‚    ssis_to_pyspark_converter.exe package.dtsx   â”‚
â”‚                                                  â”‚
â”‚  Convert Folder:                                 â”‚
â”‚    ssis_to_pyspark_converter.exe folder\        â”‚
â”‚                                                  â”‚
â”‚  View Help:                                      â”‚
â”‚    ssis_to_pyspark_converter.exe --help         â”‚
â”‚                                                  â”‚
â”‚  Output Location:                                â”‚
â”‚    output\pyspark_code\*.py                     â”‚
â”‚                                                  â”‚
â”‚  Log File:                                       â”‚
â”‚    ssis_converter.log                           â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Need help? Check ssis_converter.log or contact your administrator.**

**Version**: 1.0  
**Date**: October 2025  
**Status**: Production Ready

