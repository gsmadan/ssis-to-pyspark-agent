{
  "package_name": "Sample Simple Package",
  "mapped_connections": [
    {
      "id": "Package.ConnectionManagers[SRC_OLEDB]",
      "name": "SRC_OLEDB",
      "type": "SQL_DATABASE",
      "details": {
        "server": "localhost",
        "database": "SRC_Database",
        "provider": "SQLNCLI11.1"
      },
      "pyspark_reader": "spark.read.format(\"jdbc\")",
      "pyspark_writer": "df.write.format(\"jdbc\")",
      "options_template": {
        "url": "jdbc:sqlserver://{server}:{port};databaseName={database}",
        "driver": "com.microsoft.sqlserver.jdbc.SQLServerDriver",
        "user": "username",
        "password": "password"
      },
      "mapped": true
    },
    {
      "id": "Package.ConnectionManagers[DBX_Output]",
      "name": "DBX_Output",
      "type": "SQL_DATABASE",
      "details": {
        "server": "localhost",
        "database": "DST_Database",
        "provider": "SQLNCLI11.1"
      },
      "pyspark_reader": "spark.read.format(\"jdbc\")",
      "pyspark_writer": "df.write.format(\"jdbc\")",
      "options_template": {
        "url": "jdbc:sqlserver://{server}:{port};databaseName={database}",
        "driver": "com.microsoft.sqlserver.jdbc.SQLServerDriver",
        "user": "username",
        "password": "password"
      },
      "mapped": true
    }
  ],
  "mapped_sql_tasks": [
    {
      "task_id": "{D1E2F3A4-B5C6-4789-D012-E3456789F012}",
      "name": "SQL TRUNCATE SRC_GenericTable",
      "purpose": "TRUNCATE_TABLE",
      "sql_statement": "TRUNCATE TABLE [dbo].[SRC_GenericTable]",
      "pyspark_function": "spark.sql",
      "code_template": "\n# Truncate Table: {task_name}\nspark.sql(\"\"\"\n{sql_statement}\n\"\"\")\n",
      "mapped": true
    },
    {
      "task_id": "{F1A2B3C4-D5E6-4789-F012-A34567891234}",
      "name": "SQL Add defaults",
      "purpose": "INSERT_DATA",
      "sql_statement": "INSERT INTO [dbo].[SRC_GenericTable]\n([ID], [Name], [Value], [Status])\nVALUES (-1, 'Unknown', 0.0, 'Unknown'),\n(-2, 'Not Applicable', 0.0, 'N/A')",
      "pyspark_function": "df.write",
      "code_template": "\n# Insert Data: {task_name}\n# Use DataFrame.write instead of SQL INSERT for better performance\n# Note: SQL statement provided for reference\n\"\"\"\n{sql_statement}\n\"\"\"\n",
      "mapped": true
    }
  ],
  "mapped_data_flows": [
    {
      "task_id": "{E1F2A3B4-C5D6-4789-E012-F34567890123}",
      "name": "DFT_Load",
      "sources": [
        {
          "name": "OLE_SRC",
          "type": "OTHER",
          "table_name": "SELECT\n  [ID],\n  [Name],\n  [Value],\n  [Status]\nFROM\n  [dbo].[SRC_InputTable]",
          "pyspark_function": "spark.read.format(\"jdbc\")",
          "code_template": "\n# Read from source: {source_name}\n# Table: {table_name}\n{df_name} = spark.read \\\n    .format(\"jdbc\") \\\n    .option(\"url\", \"{jdbc_url}\") \\\n    .option(\"dbtable\", \"{table_name}\") \\\n    .option(\"user\", \"{username}\") \\\n    .option(\"password\", \"{password}\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .load()\n",
          "requires_custom": false,
          "mapped": true,
          "connection": {
            "name": "SRC_OLEDB",
            "id": "Package.ConnectionManagers[SRC_OLEDB]"
          },
          "is_sql_query": true,
          "sql_query": "SELECT\n  [ID],\n  [Name],\n  [Value],\n  [Status]\nFROM\n  [dbo].[SRC_InputTable]",
          "access_mode": "2",
          "component_id": "Package\\DFT_Load\\OLE_SRC"
        }
      ],
      "transformations": [
        {
          "name": "RC Insert",
          "type": "ROW_COUNT",
          "logic": "Transformation type: ROW_COUNT",
          "pyspark_function": "df.count",
          "code_template": "\n# Row Count: {trans_name}\n{count_var} = {input_df}.count()\nprint(f\"Row count for {trans_name}: {{count_var}}\")\n",
          "mapped": true,
          "component_id": "Package\\DFT_Load\\RC Insert",
          "component_class": "Microsoft.RowCount",
          "expressions": [],
          "outputs": [
            {
              "name": "RowCountOutput",
              "description": ""
            }
          ]
        }
      ],
      "destinations": [
        {
          "name": "OLE_DST",
          "type": "OTHER",
          "table_name": "[dbo].[SRC_GenericTable]",
          "pyspark_function": "df.write.format(\"jdbc\")",
          "code_template": "\n# Write to destination: {dest_name}\n# Assuming SQL destination\n{input_df}.write \\\n    .format(\"jdbc\") \\\n    .option(\"url\", \"{jdbc_url}\") \\\n    .option(\"dbtable\", \"{table_name}\") \\\n    .option(\"user\", \"{username}\") \\\n    .option(\"password\", \"{password}\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .mode(\"append\") \\\n    .save()\n",
          "mapped": true,
          "connection": {
            "name": "DBX_Output",
            "id": "Package.ConnectionManagers[DBX_Output]"
          },
          "component_id": "Package\\DFT_Load\\OLE_DST"
        }
      ],
      "data_flow_paths": [
        {
          "from": "OLE_SRC",
          "to": "RC Insert",
          "from_id": "Package\\DFT_Load\\OLE_SRC",
          "to_id": "Package\\DFT_Load\\RC Insert",
          "path_name": "OLE DB Source Output"
        },
        {
          "from": "RC Insert",
          "to": "OLE_DST",
          "from_id": "Package\\DFT_Load\\RC Insert",
          "to_id": "Package\\DFT_Load\\OLE_DST",
          "path_name": "RowCountOutput"
        }
      ],
      "fully_mapped": true
    }
  ],
  "execution_flow": [
    {
      "from": "SQL TRUNCATE SRC_GenericTable",
      "to": "DFT_Load",
      "from_id": "{D1E2F3A4-B5C6-4789-D012-E3456789F012}",
      "to_id": "{E1F2A3B4-C5D6-4789-E012-F34567890123}",
      "description": "Execute DFT_Load after SQL TRUNCATE SRC_GenericTable"
    },
    {
      "from": "DFT_Load",
      "to": "SQL Add defaults",
      "from_id": "{E1F2A3B4-C5D6-4789-E012-F34567890123}",
      "to_id": "{F1A2B3C4-D5E6-4789-F012-A34567891234}",
      "description": "Execute SQL Add defaults after DFT_Load"
    }
  ],
  "statistics": {
    "total_connections": 2,
    "mapped_connections": 2,
    "total_sql_tasks": 2,
    "mapped_sql_tasks": 2,
    "total_sources": 1,
    "mapped_sources": 1,
    "total_transformations": 1,
    "mapped_transformations": 1,
    "total_destinations": 1,
    "mapped_destinations": 1,
    "overall_mapping_rate": 100.0
  }
}