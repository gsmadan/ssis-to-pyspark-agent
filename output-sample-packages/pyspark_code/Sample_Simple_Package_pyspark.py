"""
PySpark conversion of SSIS Package: Sample Simple Package
Generated by SSIS-to-PySpark Converter (Databricks Optimized)
Date: 2025-11-21 12:27:10
"""

from pyspark.sql.functions import *
from pyspark.sql.types import *
import logging

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Connection Configurations (Commented - Uncomment if needed)

# Connection: SRC_OLEDB
# src_oledb_url = "jdbc:sqlserver://localhost:1433;databaseName=SRC_Database"
# src_oledb_user = "username"  # TODO: Set actual username
# src_oledb_password = "password"  # TODO: Set actual password
# src_oledb_driver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"

# Connection: DBX_Output
# dbx_output_url = "jdbc:sqlserver://localhost:1433;databaseName=DST_Database"
# dbx_output_user = "username"  # TODO: Set actual username
# dbx_output_password = "password"  # TODO: Set actual password
# dbx_output_driver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"

# =============================================================================

# CONTROL FLOW EXECUTION

# =============================================================================

# Step 1: SQL TRUNCATE SRC_GenericTable

logger.info("Step 1: Executing SQL Task - SQL TRUNCATE SRC_GenericTable")

spark.sql("""
TRUNCATE TABLE test_bronze.source.src_generictable
""")

# Step 2: DFT_Load

logger.info("Step 2: Processing Data Flow - DFT_Load")

# Source: OLE_SRC
# SQL Query: SELECT...
logger.info("Reading from source: OLE_SRC")
ole_src_df = spark.sql("""
    SELECT
  ID,
  Name,
  Value,
  Status
FROM
  test_bronze.source.src_inputtable
""")

logger.info(f"Source data loaded: { ole_src_df.count() } rows")

# Transformation: RC Insert (Row Count)
logger.info("Processing transformation: RC Insert")
rc_insert_df = ole_src_df
# Add row count logging
row_count = rc_insert_df.count()
logger.info(f"Row count: {row_count}")

# Destination: Write to Databricks table (test_silver.destination.dst_generictable)
logger.info("Writing to destination: test_silver.destination.dst_generictable")

# Write data to destination table using Delta format
rc_insert_df.write.format("delta").mode("append").saveAsTable("test_silver.destination.dst_generictable")

logger.info("Data written successfully to test_silver.destination.dst_generictable")

# Step 3: SQL Add defaults

logger.info("Step 3: Executing SQL Task - SQL Add defaults")

spark.sql("""
INSERT INTO test_bronze.source.src_generictable(ID, Name, Value, Status) VALUES (-1, 'Unknown', 0.0, 'Unknown'),
(-2, 'Not Applicable', 0.0, 'N/A')
""")

logger.info("Process completed successfully")